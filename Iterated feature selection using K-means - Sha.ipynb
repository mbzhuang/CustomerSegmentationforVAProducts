{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import cluster\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall principal of iterated feature selection\n",
    "1. Perform k-means on each of the features individually for some k. \n",
    "2. For each cluster measure some clustering performance metric like the Dunn's index or silhouette. \n",
    "3. Take the feature which gives you the best performance and add it to Sf\n",
    "4. Perform k-means on Sf and each of the remaining features individually\n",
    "5. Take the feature which gives you the best performance and add it to Sf\n",
    "4. If you have reached the desired number of features stop, else go back to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = datasets.load_iris()\n",
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 4\n"
     ]
    }
   ],
   "source": [
    "n, m = X.shape[0], X.shape[1]\n",
    "print(n, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5.4,  3.7,  1.5,  0.2],\n",
       "       [ 4.8,  3.4,  1.6,  0.2],\n",
       "       [ 4.8,  3. ,  1.4,  0.1],\n",
       "       [ 4.3,  3. ,  1.1,  0.1],\n",
       "       [ 5.8,  4. ,  1.2,  0.2],\n",
       "       [ 5.7,  4.4,  1.5,  0.4],\n",
       "       [ 5.4,  3.9,  1.3,  0.4],\n",
       "       [ 5.1,  3.5,  1.4,  0.3],\n",
       "       [ 5.7,  3.8,  1.7,  0.3],\n",
       "       [ 5.1,  3.8,  1.5,  0.3],\n",
       "       [ 5.4,  3.4,  1.7,  0.2],\n",
       "       [ 5.1,  3.7,  1.5,  0.4],\n",
       "       [ 4.6,  3.6,  1. ,  0.2],\n",
       "       [ 5.1,  3.3,  1.7,  0.5],\n",
       "       [ 4.8,  3.4,  1.9,  0.2],\n",
       "       [ 5. ,  3. ,  1.6,  0.2],\n",
       "       [ 5. ,  3.4,  1.6,  0.4],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 5.2,  3.4,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.6,  0.2],\n",
       "       [ 4.8,  3.1,  1.6,  0.2],\n",
       "       [ 5.4,  3.4,  1.5,  0.4],\n",
       "       [ 5.2,  4.1,  1.5,  0.1],\n",
       "       [ 5.5,  4.2,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5. ,  3.2,  1.2,  0.2],\n",
       "       [ 5.5,  3.5,  1.3,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 4.4,  3. ,  1.3,  0.2],\n",
       "       [ 5.1,  3.4,  1.5,  0.2],\n",
       "       [ 5. ,  3.5,  1.3,  0.3],\n",
       "       [ 4.5,  2.3,  1.3,  0.3],\n",
       "       [ 4.4,  3.2,  1.3,  0.2],\n",
       "       [ 5. ,  3.5,  1.6,  0.6],\n",
       "       [ 5.1,  3.8,  1.9,  0.4],\n",
       "       [ 4.8,  3. ,  1.4,  0.3],\n",
       "       [ 5.1,  3.8,  1.6,  0.2],\n",
       "       [ 4.6,  3.2,  1.4,  0.2],\n",
       "       [ 5.3,  3.7,  1.5,  0.2],\n",
       "       [ 5. ,  3.3,  1.4,  0.2],\n",
       "       [ 7. ,  3.2,  4.7,  1.4],\n",
       "       [ 6.4,  3.2,  4.5,  1.5],\n",
       "       [ 6.9,  3.1,  4.9,  1.5],\n",
       "       [ 5.5,  2.3,  4. ,  1.3],\n",
       "       [ 6.5,  2.8,  4.6,  1.5],\n",
       "       [ 5.7,  2.8,  4.5,  1.3],\n",
       "       [ 6.3,  3.3,  4.7,  1.6],\n",
       "       [ 4.9,  2.4,  3.3,  1. ],\n",
       "       [ 6.6,  2.9,  4.6,  1.3],\n",
       "       [ 5.2,  2.7,  3.9,  1.4],\n",
       "       [ 5. ,  2. ,  3.5,  1. ],\n",
       "       [ 5.9,  3. ,  4.2,  1.5],\n",
       "       [ 6. ,  2.2,  4. ,  1. ],\n",
       "       [ 6.1,  2.9,  4.7,  1.4],\n",
       "       [ 5.6,  2.9,  3.6,  1.3],\n",
       "       [ 6.7,  3.1,  4.4,  1.4],\n",
       "       [ 5.6,  3. ,  4.5,  1.5],\n",
       "       [ 5.8,  2.7,  4.1,  1. ],\n",
       "       [ 6.2,  2.2,  4.5,  1.5],\n",
       "       [ 5.6,  2.5,  3.9,  1.1],\n",
       "       [ 5.9,  3.2,  4.8,  1.8],\n",
       "       [ 6.1,  2.8,  4. ,  1.3],\n",
       "       [ 6.3,  2.5,  4.9,  1.5],\n",
       "       [ 6.1,  2.8,  4.7,  1.2],\n",
       "       [ 6.4,  2.9,  4.3,  1.3],\n",
       "       [ 6.6,  3. ,  4.4,  1.4],\n",
       "       [ 6.8,  2.8,  4.8,  1.4],\n",
       "       [ 6.7,  3. ,  5. ,  1.7],\n",
       "       [ 6. ,  2.9,  4.5,  1.5],\n",
       "       [ 5.7,  2.6,  3.5,  1. ],\n",
       "       [ 5.5,  2.4,  3.8,  1.1],\n",
       "       [ 5.5,  2.4,  3.7,  1. ],\n",
       "       [ 5.8,  2.7,  3.9,  1.2],\n",
       "       [ 6. ,  2.7,  5.1,  1.6],\n",
       "       [ 5.4,  3. ,  4.5,  1.5],\n",
       "       [ 6. ,  3.4,  4.5,  1.6],\n",
       "       [ 6.7,  3.1,  4.7,  1.5],\n",
       "       [ 6.3,  2.3,  4.4,  1.3],\n",
       "       [ 5.6,  3. ,  4.1,  1.3],\n",
       "       [ 5.5,  2.5,  4. ,  1.3],\n",
       "       [ 5.5,  2.6,  4.4,  1.2],\n",
       "       [ 6.1,  3. ,  4.6,  1.4],\n",
       "       [ 5.8,  2.6,  4. ,  1.2],\n",
       "       [ 5. ,  2.3,  3.3,  1. ],\n",
       "       [ 5.6,  2.7,  4.2,  1.3],\n",
       "       [ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 5.7,  2.9,  4.2,  1.3],\n",
       "       [ 6.2,  2.9,  4.3,  1.3],\n",
       "       [ 5.1,  2.5,  3. ,  1.1],\n",
       "       [ 5.7,  2.8,  4.1,  1.3],\n",
       "       [ 6.3,  3.3,  6. ,  2.5],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 7.1,  3. ,  5.9,  2.1],\n",
       "       [ 6.3,  2.9,  5.6,  1.8],\n",
       "       [ 6.5,  3. ,  5.8,  2.2],\n",
       "       [ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 4.9,  2.5,  4.5,  1.7],\n",
       "       [ 7.3,  2.9,  6.3,  1.8],\n",
       "       [ 6.7,  2.5,  5.8,  1.8],\n",
       "       [ 7.2,  3.6,  6.1,  2.5],\n",
       "       [ 6.5,  3.2,  5.1,  2. ],\n",
       "       [ 6.4,  2.7,  5.3,  1.9],\n",
       "       [ 6.8,  3. ,  5.5,  2.1],\n",
       "       [ 5.7,  2.5,  5. ,  2. ],\n",
       "       [ 5.8,  2.8,  5.1,  2.4],\n",
       "       [ 6.4,  3.2,  5.3,  2.3],\n",
       "       [ 6.5,  3. ,  5.5,  1.8],\n",
       "       [ 7.7,  3.8,  6.7,  2.2],\n",
       "       [ 7.7,  2.6,  6.9,  2.3],\n",
       "       [ 6. ,  2.2,  5. ,  1.5],\n",
       "       [ 6.9,  3.2,  5.7,  2.3],\n",
       "       [ 5.6,  2.8,  4.9,  2. ],\n",
       "       [ 7.7,  2.8,  6.7,  2. ],\n",
       "       [ 6.3,  2.7,  4.9,  1.8],\n",
       "       [ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 7.2,  3.2,  6. ,  1.8],\n",
       "       [ 6.2,  2.8,  4.8,  1.8],\n",
       "       [ 6.1,  3. ,  4.9,  1.8],\n",
       "       [ 6.4,  2.8,  5.6,  2.1],\n",
       "       [ 7.2,  3. ,  5.8,  1.6],\n",
       "       [ 7.4,  2.8,  6.1,  1.9],\n",
       "       [ 7.9,  3.8,  6.4,  2. ],\n",
       "       [ 6.4,  2.8,  5.6,  2.2],\n",
       "       [ 6.3,  2.8,  5.1,  1.5],\n",
       "       [ 6.1,  2.6,  5.6,  1.4],\n",
       "       [ 7.7,  3. ,  6.1,  2.3],\n",
       "       [ 6.3,  3.4,  5.6,  2.4],\n",
       "       [ 6.4,  3.1,  5.5,  1.8],\n",
       "       [ 6. ,  3. ,  4.8,  1.8],\n",
       "       [ 6.9,  3.1,  5.4,  2.1],\n",
       "       [ 6.7,  3.1,  5.6,  2.4],\n",
       "       [ 6.9,  3.1,  5.1,  2.3],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 6.8,  3.2,  5.9,  2.3],\n",
       "       [ 6.7,  3.3,  5.7,  2.5],\n",
       "       [ 6.7,  3. ,  5.2,  2.3],\n",
       "       [ 6.3,  2.5,  5. ,  1.9],\n",
       "       [ 6.5,  3. ,  5.2,  2. ],\n",
       "       [ 6.2,  3.4,  5.4,  2.3],\n",
       "       [ 5.9,  3. ,  5.1,  1.8]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(pd.Series(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection - code version 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perform k-means on each of the features individually for some k. \n",
    "* For each cluster measure some clustering performance metric like the Dunn's index or silhouette. \n",
    "* Take the feature which gives you the best performance and add it to Sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in range(1,5):\n",
    "    exec(f'X{d} = np.zeros(n)')\n",
    "    for i in range(n):\n",
    "        exec(f'X{d}[i] = X[i][d-1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing model 1 , which uses feature # 1 only\n",
      "Now let's compare the true class label to the class labels obtained by clustering\n",
      "2    63\n",
      "1    52\n",
      "0    35\n",
      "dtype: int64\n",
      "For model 1: the sum of squared distances of samples to their closest cluster center is 15.7581196581\n",
      "Now processing model 2 , which uses feature # 2 only\n",
      "Now let's compare the true class label to the class labels obtained by clustering\n",
      "1    81\n",
      "0    36\n",
      "2    33\n",
      "dtype: int64\n",
      "For model 2: the sum of squared distances of samples to their closest cluster center is 5.26434343434\n",
      "Now processing model 3 , which uses feature # 3 only\n",
      "Now let's compare the true class label to the class labels obtained by clustering\n",
      "0    58\n",
      "1    50\n",
      "2    42\n",
      "dtype: int64\n",
      "For model 3: the sum of squared distances of samples to their closest cluster center is 24.6580407225\n",
      "Now processing model 4 , which uses feature # 4 only\n",
      "Now let's compare the true class label to the class labels obtained by clustering\n",
      "2    52\n",
      "0    50\n",
      "1    48\n",
      "dtype: int64\n",
      "For model 4: the sum of squared distances of samples to their closest cluster center is 4.93217435897\n"
     ]
    }
   ],
   "source": [
    "score = [0]*m\n",
    "for i in range(1, m+1):\n",
    "    print(\"Now processing model %d\" %i, \", which uses feature # %d only\" %i)\n",
    "    exec(f'model_{i} = cluster.KMeans(n_clusters=3)')\n",
    "    exec(f'X{i} = X{i}[:, np.newaxis]')\n",
    "    exec(f'model_{i}.fit(X{i})')\n",
    "    exec(f'pred_y = model_{i}.labels_')\n",
    "    print(\"Now let's compare the true class label to the class labels obtained by clustering\")\n",
    "    print(pd.value_counts(pd.Series(pred_y)))\n",
    "    exec(f'score[i-1] = model_{i}.inertia_')\n",
    "    print(\"For model %d:\" %i,\"the sum of squared distances of samples to their closest cluster center is %s\" %score[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The # 4 feature gives the best performance\n"
     ]
    }
   ],
   "source": [
    "selected_feature = score.index(min(score)) + 1\n",
    "print(\"The # %d feature\" % (score.index(min(score)) + 1), \"gives the best performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perform k-means on Sf and each of the remaining features individually\n",
    "* Take the feature which gives you the best performance and add it to Sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score1 = [0]*m\n",
    "for i in range(1, m+1):\n",
    "    if i!= selected_feature:\n",
    "        second_iter_X{i} = np.concatenate((X1{i}, X{selected_feature}), axis=1)\n",
    "X        \n",
    "#     print(\"Now processing model %d\" %i, \", which uses feature # %d only\" %i)\n",
    "#     exec(f'model_{i} = cluster.KMeans(n_clusters=3)')\n",
    "#     exec(f'X{i} = X{i}[:, np.newaxis]')\n",
    "#     exec(f'model_{i}.fit(X{i})')\n",
    "#     exec(f'pred_y = model_{i}.labels_')\n",
    "#     print(\"Now let's compare the true class label to the class labels obtained by clustering\")\n",
    "#     print(pd.value_counts(pd.Series(pred_y)))\n",
    "#     exec(f'score[i-1] = model_{i}.inertia_')\n",
    "#     print(\"For model %d:\" %i,\"the sum of squared distances of samples to their closest cluster center is %s\" %score[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5],\n",
       "       [ 4.9,  3. ],\n",
       "       [ 4.7,  3.2],\n",
       "       [ 4.6,  3.1],\n",
       "       [ 5. ,  3.6],\n",
       "       [ 5.4,  3.9],\n",
       "       [ 4.6,  3.4],\n",
       "       [ 5. ,  3.4],\n",
       "       [ 4.4,  2.9],\n",
       "       [ 4.9,  3.1],\n",
       "       [ 5.4,  3.7],\n",
       "       [ 4.8,  3.4],\n",
       "       [ 4.8,  3. ],\n",
       "       [ 4.3,  3. ],\n",
       "       [ 5.8,  4. ],\n",
       "       [ 5.7,  4.4],\n",
       "       [ 5.4,  3.9],\n",
       "       [ 5.1,  3.5],\n",
       "       [ 5.7,  3.8],\n",
       "       [ 5.1,  3.8],\n",
       "       [ 5.4,  3.4],\n",
       "       [ 5.1,  3.7],\n",
       "       [ 4.6,  3.6],\n",
       "       [ 5.1,  3.3],\n",
       "       [ 4.8,  3.4],\n",
       "       [ 5. ,  3. ],\n",
       "       [ 5. ,  3.4],\n",
       "       [ 5.2,  3.5],\n",
       "       [ 5.2,  3.4],\n",
       "       [ 4.7,  3.2],\n",
       "       [ 4.8,  3.1],\n",
       "       [ 5.4,  3.4],\n",
       "       [ 5.2,  4.1],\n",
       "       [ 5.5,  4.2],\n",
       "       [ 4.9,  3.1],\n",
       "       [ 5. ,  3.2],\n",
       "       [ 5.5,  3.5],\n",
       "       [ 4.9,  3.1],\n",
       "       [ 4.4,  3. ],\n",
       "       [ 5.1,  3.4],\n",
       "       [ 5. ,  3.5],\n",
       "       [ 4.5,  2.3],\n",
       "       [ 4.4,  3.2],\n",
       "       [ 5. ,  3.5],\n",
       "       [ 5.1,  3.8],\n",
       "       [ 4.8,  3. ],\n",
       "       [ 5.1,  3.8],\n",
       "       [ 4.6,  3.2],\n",
       "       [ 5.3,  3.7],\n",
       "       [ 5. ,  3.3],\n",
       "       [ 7. ,  3.2],\n",
       "       [ 6.4,  3.2],\n",
       "       [ 6.9,  3.1],\n",
       "       [ 5.5,  2.3],\n",
       "       [ 6.5,  2.8],\n",
       "       [ 5.7,  2.8],\n",
       "       [ 6.3,  3.3],\n",
       "       [ 4.9,  2.4],\n",
       "       [ 6.6,  2.9],\n",
       "       [ 5.2,  2.7],\n",
       "       [ 5. ,  2. ],\n",
       "       [ 5.9,  3. ],\n",
       "       [ 6. ,  2.2],\n",
       "       [ 6.1,  2.9],\n",
       "       [ 5.6,  2.9],\n",
       "       [ 6.7,  3.1],\n",
       "       [ 5.6,  3. ],\n",
       "       [ 5.8,  2.7],\n",
       "       [ 6.2,  2.2],\n",
       "       [ 5.6,  2.5],\n",
       "       [ 5.9,  3.2],\n",
       "       [ 6.1,  2.8],\n",
       "       [ 6.3,  2.5],\n",
       "       [ 6.1,  2.8],\n",
       "       [ 6.4,  2.9],\n",
       "       [ 6.6,  3. ],\n",
       "       [ 6.8,  2.8],\n",
       "       [ 6.7,  3. ],\n",
       "       [ 6. ,  2.9],\n",
       "       [ 5.7,  2.6],\n",
       "       [ 5.5,  2.4],\n",
       "       [ 5.5,  2.4],\n",
       "       [ 5.8,  2.7],\n",
       "       [ 6. ,  2.7],\n",
       "       [ 5.4,  3. ],\n",
       "       [ 6. ,  3.4],\n",
       "       [ 6.7,  3.1],\n",
       "       [ 6.3,  2.3],\n",
       "       [ 5.6,  3. ],\n",
       "       [ 5.5,  2.5],\n",
       "       [ 5.5,  2.6],\n",
       "       [ 6.1,  3. ],\n",
       "       [ 5.8,  2.6],\n",
       "       [ 5. ,  2.3],\n",
       "       [ 5.6,  2.7],\n",
       "       [ 5.7,  3. ],\n",
       "       [ 5.7,  2.9],\n",
       "       [ 6.2,  2.9],\n",
       "       [ 5.1,  2.5],\n",
       "       [ 5.7,  2.8],\n",
       "       [ 6.3,  3.3],\n",
       "       [ 5.8,  2.7],\n",
       "       [ 7.1,  3. ],\n",
       "       [ 6.3,  2.9],\n",
       "       [ 6.5,  3. ],\n",
       "       [ 7.6,  3. ],\n",
       "       [ 4.9,  2.5],\n",
       "       [ 7.3,  2.9],\n",
       "       [ 6.7,  2.5],\n",
       "       [ 7.2,  3.6],\n",
       "       [ 6.5,  3.2],\n",
       "       [ 6.4,  2.7],\n",
       "       [ 6.8,  3. ],\n",
       "       [ 5.7,  2.5],\n",
       "       [ 5.8,  2.8],\n",
       "       [ 6.4,  3.2],\n",
       "       [ 6.5,  3. ],\n",
       "       [ 7.7,  3.8],\n",
       "       [ 7.7,  2.6],\n",
       "       [ 6. ,  2.2],\n",
       "       [ 6.9,  3.2],\n",
       "       [ 5.6,  2.8],\n",
       "       [ 7.7,  2.8],\n",
       "       [ 6.3,  2.7],\n",
       "       [ 6.7,  3.3],\n",
       "       [ 7.2,  3.2],\n",
       "       [ 6.2,  2.8],\n",
       "       [ 6.1,  3. ],\n",
       "       [ 6.4,  2.8],\n",
       "       [ 7.2,  3. ],\n",
       "       [ 7.4,  2.8],\n",
       "       [ 7.9,  3.8],\n",
       "       [ 6.4,  2.8],\n",
       "       [ 6.3,  2.8],\n",
       "       [ 6.1,  2.6],\n",
       "       [ 7.7,  3. ],\n",
       "       [ 6.3,  3.4],\n",
       "       [ 6.4,  3.1],\n",
       "       [ 6. ,  3. ],\n",
       "       [ 6.9,  3.1],\n",
       "       [ 6.7,  3.1],\n",
       "       [ 6.9,  3.1],\n",
       "       [ 5.8,  2.7],\n",
       "       [ 6.8,  3.2],\n",
       "       [ 6.7,  3.3],\n",
       "       [ 6.7,  3. ],\n",
       "       [ 6.3,  2.5],\n",
       "       [ 6.5,  3. ],\n",
       "       [ 6.2,  3.4],\n",
       "       [ 5.9,  3. ]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((X1, X2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection - code version 2\n",
    "#### Try to organize data into functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_selection(m, n, X, num_clusters, desired_num_of_feature):\n",
    "    for i in range(desired_num_of_feature):\n",
    "        # The first iteration, perform k-means on each of the features individually and \n",
    "        # take the feature which gives you the best performance   \n",
    "        if i == 0:\n",
    "            #generate data points X_iter_1 with only one feature\n",
    "            for d in range(1, n+1):\n",
    "                exec(f 'X_iter{i+1}_{d} = np.zeros(n)') \n",
    "                #reference: https://stackoverflow.com/questions/6181935/how-do-you-create-different-variable-names-while-in-a-loop\n",
    "                #https://docs.python.org/3/whatsnew/3.6.html\n",
    "                \n",
    "                for j in range(n):\n",
    "                    exec(f'X_iter{i+1}_{d}[j] = X[j][d-1]')\n",
    "            \n",
    "            #Now perform k-means on each of the featurees individually \n",
    "            for j in range(1, m+1):\n",
    "                print(\"Now processing model %d\" %j, \", which uses feature # %d only\" %j)\n",
    "                exec(f'model_{j} = cluster.KMeans(n_clusters=num_clusters)')\n",
    "                # Need to add a dimension to the generate data points in order to fit model\n",
    "                exec(f'X_iter{i+1}_{j} = X{j}[:, np.newaxis]')\n",
    "                # Now fit the data points with only one feature\n",
    "                exec(f'model_{i}.fit(X{i})')\n",
    "                exec(f'pred_y = model_{i}.labels_')\n",
    "                print(\"Now let's compare the true class label to the class labels obtained by clustering\")\n",
    "                print(pd.value_counts(pd.Series(pred_y)))\n",
    "                exec(f'score[i-1] = model_{i}.inertia_')\n",
    "                print(\"For model %d:\" %i,\"the sum of squared distances of samples to their closest cluster center is %s\" %score[i-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection - code version 3\n",
    "#### Organize Iris dataset into a dataframe in order to better imitate our project data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = datasets.load_iris()\n",
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'target', 'target_names']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = pd.DataFrame(X)\n",
    "iris.columns = dataset.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "5                  5.4               3.9                1.7               0.4\n",
       "6                  4.6               3.4                1.4               0.3\n",
       "7                  5.0               3.4                1.5               0.2\n",
       "8                  4.4               2.9                1.4               0.2\n",
       "9                  4.9               3.1                1.5               0.1\n",
       "10                 5.4               3.7                1.5               0.2\n",
       "11                 4.8               3.4                1.6               0.2\n",
       "12                 4.8               3.0                1.4               0.1\n",
       "13                 4.3               3.0                1.1               0.1\n",
       "14                 5.8               4.0                1.2               0.2\n",
       "15                 5.7               4.4                1.5               0.4\n",
       "16                 5.4               3.9                1.3               0.4\n",
       "17                 5.1               3.5                1.4               0.3\n",
       "18                 5.7               3.8                1.7               0.3\n",
       "19                 5.1               3.8                1.5               0.3\n",
       "20                 5.4               3.4                1.7               0.2\n",
       "21                 5.1               3.7                1.5               0.4\n",
       "22                 4.6               3.6                1.0               0.2\n",
       "23                 5.1               3.3                1.7               0.5\n",
       "24                 4.8               3.4                1.9               0.2\n",
       "25                 5.0               3.0                1.6               0.2\n",
       "26                 5.0               3.4                1.6               0.4\n",
       "27                 5.2               3.5                1.5               0.2\n",
       "28                 5.2               3.4                1.4               0.2\n",
       "29                 4.7               3.2                1.6               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "120                6.9               3.2                5.7               2.3\n",
       "121                5.6               2.8                4.9               2.0\n",
       "122                7.7               2.8                6.7               2.0\n",
       "123                6.3               2.7                4.9               1.8\n",
       "124                6.7               3.3                5.7               2.1\n",
       "125                7.2               3.2                6.0               1.8\n",
       "126                6.2               2.8                4.8               1.8\n",
       "127                6.1               3.0                4.9               1.8\n",
       "128                6.4               2.8                5.6               2.1\n",
       "129                7.2               3.0                5.8               1.6\n",
       "130                7.4               2.8                6.1               1.9\n",
       "131                7.9               3.8                6.4               2.0\n",
       "132                6.4               2.8                5.6               2.2\n",
       "133                6.3               2.8                5.1               1.5\n",
       "134                6.1               2.6                5.6               1.4\n",
       "135                7.7               3.0                6.1               2.3\n",
       "136                6.3               3.4                5.6               2.4\n",
       "137                6.4               3.1                5.5               1.8\n",
       "138                6.0               3.0                4.8               1.8\n",
       "139                6.9               3.1                5.4               2.1\n",
       "140                6.7               3.1                5.6               2.4\n",
       "141                6.9               3.1                5.1               2.3\n",
       "142                5.8               2.7                5.1               1.9\n",
       "143                6.8               3.2                5.9               2.3\n",
       "144                6.7               3.3                5.7               2.5\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data points: 150 . number of variables: 4\n"
     ]
    }
   ],
   "source": [
    "n, m = iris.shape[0], iris.shape[1]\n",
    "print(\"number of data points:\", n, \". number of variables:\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True class labels \n",
      " 2    50\n",
      "1    50\n",
      "0    50\n",
      "dtype: int64\n",
      "Clustered class labels: \n",
      " 0    62\n",
      "1    50\n",
      "2    38\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "model_test = cluster.KMeans(n_clusters=3)\n",
    "model_test.fit(iris) \n",
    "pred_y=model_test.labels_\n",
    "print(\"True class labels\", \"\\n\", pd.value_counts(pd.Series(y)))\n",
    "print(\"Clustered class labels:\", \"\\n\", pd.value_counts(pd.Series(pred_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = np.zeros([num_of_iter, m])\n",
    "# score = pd.DataFrame(score)\n",
    "# score.loc[:,0:2]\n",
    "score[:, [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exclude_columns = [3]\n",
    "include_columns = [i for i in range(np.shape(score)[1]) if i not in exclude_columns]\n",
    "extractedData = score[:,include_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['petal width (cm)', 'sepal width (cm)', 'sepal width (cm)'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.columns[exclude_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 1]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude_columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'None of [[3, 1, 0]] are in the [columns]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f913e9b7ae94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude_columns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1311\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[1;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[1;31m# ugly hack for GH #836\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Too many indexers'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m                 raise ValueError(\"Location based indexing can only have [%s] \"\n\u001b[1;32m    153\u001b[0m                                  \"types\" % self._valid_types)\n",
      "\u001b[0;32mC:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m                 raise KeyError(\"None of [%s] are in the [%s]\" %\n\u001b[0;32m-> 1395\u001b[0;31m                                (key, self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'None of [[3, 1, 0]] are in the [columns]'"
     ]
    }
   ],
   "source": [
    "iris.loc[:, exclude_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing iteration 0 \n",
      "\n",
      "cluster labels based on variable sepal length (cm): \n",
      " 2    63\n",
      "0    52\n",
      "1    35\n",
      "dtype: int64\n",
      "the sum of squared distances of samples to their closest cluster center based on variable sepal length (cm) is: 15.7581196581\n",
      "cluster labels based on variable sepal width (cm): \n",
      " 0    81\n",
      "1    36\n",
      "2    33\n",
      "dtype: int64\n",
      "the sum of squared distances of samples to their closest cluster center based on variable sepal width (cm) is: 5.26434343434\n",
      "cluster labels based on variable petal length (cm): \n",
      " 2    54\n",
      "0    50\n",
      "1    46\n",
      "dtype: int64\n",
      "the sum of squared distances of samples to their closest cluster center based on variable petal length (cm) is: 24.5138312399\n",
      "cluster labels based on variable petal width (cm): \n",
      " 0    52\n",
      "1    50\n",
      "2    48\n",
      "dtype: int64\n",
      "the sum of squared distances of samples to their closest cluster center based on variable petal width (cm) is: 4.93217435897\n",
      "Conclusion: cluster based on variable petal width (cm) gives the best performance \n",
      "\n",
      "Now processing iteration 1 \n",
      "\n",
      "cluster labels based on variables: Index(['petal width (cm)', 'sepal length (cm)'], dtype='object') \n",
      " 1    54\n",
      "0    52\n",
      "2    44\n",
      "dtype: int64\n",
      "the sum of squared distances of samples to their closest cluster center based on variables: Index(['petal width (cm)', 'sepal length (cm)'], dtype='object') is: 32.7570817146\n",
      "cluster labels based on variables: Index(['petal width (cm)', 'sepal width (cm)'], dtype='object') \n",
      " 2    53\n",
      "1    49\n",
      "0    48\n",
      "dtype: int64\n",
      "the sum of squared distances of samples to their closest cluster center based on variables: Index(['petal width (cm)', 'sepal width (cm)'], dtype='object') is: 20.7170898312\n",
      "cluster labels based on variables: Index(['petal width (cm)', 'petal length (cm)'], dtype='object') \n",
      " 0    52\n",
      "1    50\n",
      "2    48\n",
      "dtype: int64\n",
      "the sum of squared distances of samples to their closest cluster center based on variables: Index(['petal width (cm)', 'petal length (cm)'], dtype='object') is: 31.3877589744\n",
      "Conclusion: cluster based on variable Index(['petal width (cm)', 'sepal width (cm)'], dtype='object') gives the best performance \n",
      "\n",
      "Now processing iteration 2 \n",
      "\n",
      "cluster labels based on variables: Index(['petal width (cm)', 'sepal width (cm)', 'sepal length (cm)'], dtype='object') \n",
      " 2    54\n",
      "0    50\n",
      "1    46\n",
      "dtype: int64\n",
      "the sum of squared distances of samples to their closest cluster center based on variables: Index(['petal width (cm)', 'sepal width (cm)', 'sepal length (cm)'], dtype='object') is: 48.7527845411\n",
      "cluster labels based on variables: Index(['petal width (cm)', 'sepal width (cm)', 'petal length (cm)'], dtype='object') \n",
      " 0    53\n",
      "1    50\n",
      "2    47\n",
      "dtype: int64\n",
      "the sum of squared distances of samples to their closest cluster center based on variables: Index(['petal width (cm)', 'sepal width (cm)', 'petal length (cm)'], dtype='object') is: 47.9558290646\n",
      "Conclusion: cluster based on variable Index(['petal width (cm)', 'sepal width (cm)', 'sepal width (cm)'], dtype='object') gives the best performance \n",
      "\n",
      "Selected features are Index(['petal width (cm)', 'sepal width (cm)', 'sepal width (cm)'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# let's assume there are 3 clusters\n",
    "num_of_cluster = 3\n",
    "num_of_iter = 3\n",
    "model = cluster.KMeans(n_clusters=num_of_cluster)\n",
    "score = np.zeros([num_of_iter, m])\n",
    "exclude_columns = []\n",
    "include_columns = [i for i in range(np.shape(score)[1]) if i not in exclude_columns]\n",
    "# Let's assume we're going to select 3 features out of 4 features, therefore we're going to iterate 3 times\n",
    "for iteration in range(3):\n",
    "    # The first iteration, we're going to test clustering models on each individual variables\n",
    "    if iteration == 0:\n",
    "        print(\"Now processing iteration %d\" %iteration, \"\\n\")   \n",
    "        for i in range(m):\n",
    "            model.fit(iris[[i]])\n",
    "            pred_y = model.labels_\n",
    "            print(\"cluster labels based on variable %s:\" %iris.columns[i], \"\\n\", pd.value_counts(pd.Series(pred_y)))\n",
    "            score[iteration][i] = model.inertia_\n",
    "            print(\"the sum of squared distances of samples to their closest cluster center based on variable %s\" \\\n",
    "                  %iris.columns[i], \"is:\", score[iteration][i])   \n",
    "        score = score[:,include_columns]\n",
    "        selected_feature_index = np.argmin(score[iteration], axis=0) \n",
    "        selected_feature_score = np.amin(score[iteration], axis=0) \n",
    "        selected_feature = iris[[selected_feature_index]]\n",
    "        exclude_columns.append(selected_feature_index)\n",
    "        print(\"Conclusion: cluster based on variable %s\" %iris.columns[selected_feature_index], \"gives the best performance\", \"\\n\") \n",
    "    #for following iteration, we're going to add the rest the feature to the selected feature and perform cluster model\n",
    "    else:\n",
    "        print(\"Now processing iteration %d\" %iteration, \"\\n\") \n",
    "        for i in range(m):\n",
    "            if i not in exclude_columns:\n",
    "                \n",
    "                data = pd.concat([selected_feature, iris[[i]]], axis=1)\n",
    "                model.fit(data)\n",
    "                pred_y = model.labels_\n",
    "                print(\"cluster labels based on variables:\", data.columns, \"\\n\", pd.value_counts(pd.Series(pred_y)))\n",
    "                score[iteration][i] = model.inertia_\n",
    "                print(\"the sum of squared distances of samples to their closest cluster center based on variables:\", \\\n",
    "                 data.columns, \"is:\", score[iteration][i]) \n",
    "        include_columns = [i for i in range(np.shape(score)[1]) if i not in exclude_columns]\n",
    "        score = score[:,include_columns]\n",
    "        selected_feature_index = np.argmin(score[iteration], axis=0) \n",
    "        selected_feature_score = np.amin(score[iteration], axis=0) \n",
    "        selected_feature = pd.concat([selected_feature, iris[[selected_feature_index]]], axis=1)\n",
    "        exclude_columns.append(selected_feature_index)\n",
    "        print(\"Conclusion: cluster based on variable %s\" %iris.columns[exclude_columns], \"gives the best performance\", \"\\n\") \n",
    "print(\"Selected features are %s\" %iris.columns[exclude_columns])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
