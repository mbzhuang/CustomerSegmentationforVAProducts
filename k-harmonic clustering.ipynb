{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('cluster.csv', header = None)\n",
    "\n",
    "# convert dataframe into numpy array\n",
    "X = df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize the data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_sc = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Define a function to calculate distances to centroids for all data points - can be further optimized (with the np.vectorize function etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance(points1, points2):\n",
    "    distances = np.zeros(shape=(points1.shape[0], points2.shape[0]))\n",
    "    distanceToCentroids = lambda point: \\\n",
    "        np.array([np.linalg.norm(point - centroid) for centroid in points2],dtype = float)\n",
    "\n",
    "    # Loop over data points:\n",
    "    for i in range(points1.shape[0]):\n",
    "        distances[i,] = distanceToCentroids(points1[i, ])\n",
    "    \n",
    "    return(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the function to iteratively get find the cluster centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def khmeans(X, n_clusters, p=2, max_iter=100, tol=1e-4):\n",
    "        \n",
    "    # X : array-like matrix, already standardized\n",
    "    n_samples = X.shape[0]\n",
    "    n_features = X.shape[1]\n",
    "        \n",
    "    # initialize centroids randomly\n",
    "    centroids = X[random.sample(range(n_samples), n_clusters), ]\n",
    "    \n",
    "    # initialize an array to store the memebership values for all data points\n",
    "    membership = np.zeros(shape=(n_samples, n_clusters))\n",
    "    \n",
    "    # initialize an array to store values of weight for all data points\n",
    "    weight = np.zeros(shape=(n_samples, ))\n",
    "    \n",
    "    # initialize upper and lower part of the new center location calculation formula\n",
    "    c_upper = np.zeros(shape=(n_clusters, n_features))\n",
    "    c_lower = np.zeros(shape=(n_clusters, ))\n",
    "    \n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        \n",
    "        # calculate the objective function values of the KHM algorithm\n",
    "        distances = distance(X, centroids)\n",
    "        reciprocal = np.reciprocal(distances**p)\n",
    "        reciprocal[np.isinf(reciprocal)] = 0\n",
    "        obj = np.sum(n_clusters / np.sum(reciprocal, axis=1))\n",
    "        \n",
    "        # calculate the the grade of membership value of each data point to each centroid\n",
    "        d = distances**(-1)\n",
    "        d[np.isinf(d)] = 0\n",
    "        for i in range(n_samples): \n",
    "            membership[i,] = (d**(p+2))[i]/np.sum(d**(p+2), axis=1)[i]\n",
    "            \n",
    "        # calculate the weight of each data point\n",
    "        for i in range(n_samples):\n",
    "            weight[i] = np.sum(d**(p+2), axis=1)[i]/(np.sum(d**p, axis=1)[i])**2\n",
    "        \n",
    "        # calculate the new center location with the membership and weight of each point\n",
    "        for i in range(n_samples):\n",
    "            c_upper += np.matmul((membership[i]*weight[i]).reshape(n_clusters,1),X[i].reshape(1,n_features))\n",
    "            c_lower += membership[i]*weight[i]\n",
    "        \n",
    "        for i in range(len(c_upper)):\n",
    "            centroids[i] = c_upper[i]/c_lower[i]\n",
    "            \n",
    "        obj_previous = obj\n",
    "        distances = distance(X, centroids)\n",
    "        labels = np.argmin(distances, axis = 1)\n",
    "        reciprocal = np.reciprocal(distances**p)\n",
    "        reciprocal[np.isinf(reciprocal)] = 0\n",
    "        obj = np.sum(n_clusters / np.sum(reciprocal, axis=1))\n",
    "        \n",
    "            \n",
    "        # stop if the objective function does not change significantly    \n",
    "        if (np.linalg.norm(obj - obj_previous) < tol):\n",
    "            break  \n",
    "        \n",
    "    return(centroids, obj, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the silhouette scores for each data point based on the new clusters\n",
    "\n",
    "def silhouettes(labels, n_samples):\n",
    "    \n",
    "    # initiate an array to store the silhouette scores for all data points\n",
    "    silhouette = np.zeros(shape=(n_samples, ))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        a_i = np.average(np.ma.masked_equal(distance(X[labels == labels[i,], ], X[i:i+1,]),0))\n",
    "        b_i = np.min(distance(X[labels != labels[i,], ], X[i:i+1,]))\n",
    "        silhouette[i,] = (b_i - a_i)/np.max([a_i, b_i])\n",
    "    return(silhouette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YAWEN\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "C:\\Users\\YAWEN\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in reciprocal\n"
     ]
    }
   ],
   "source": [
    "centroids, obj, labels = khmeans(X_sc, n_clusters=3, p=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "silhouette_avg = silhouette_score(X_sc, labels)\n",
    "sample_silhouette_values = silhouette_samples(X_sc, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84040314629599244"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YAWEN\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: np.average currently does not preserve subclasses, but will do so in the future to match the behavior of most other numpy functions such as np.mean. In particular, this means calls which returned a scalar may return a 0-d subclass object instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84465510417649192"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(silhouettes(labels=labels, n_samples=X_sc.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YAWEN\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: np.average currently does not preserve subclasses, but will do so in the future to match the behavior of most other numpy functions such as np.mean. In particular, this means calls which returned a scalar may return a 0-d subclass object instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.        ,  2.        ,  2.        ,  2.        ,  2.        ,\n",
       "         2.        ,  2.        ,  2.        ,  2.        ,  2.        ,\n",
       "         2.        ,  2.        ,  2.        ,  2.        ,  2.        ,\n",
       "         2.        ,  2.        ,  2.        ,  2.        ,  2.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ],\n",
       "       [ 0.85870553,  0.86266847,  0.87048271,  0.86510725,  0.85929719,\n",
       "         0.86006186,  0.85892299,  0.87218171,  0.86466464,  0.87175238,\n",
       "         0.87020031,  0.87601984,  0.86389394,  0.87660901,  0.85989491,\n",
       "         0.86614285,  0.8759396 ,  0.87007121,  0.87690915,  0.86266888,\n",
       "         0.71373426,  0.7419216 ,  0.75348624,  0.747457  ,  0.71437972,\n",
       "         0.75063565,  0.74925082,  0.72342908,  0.75151088,  0.75128452,\n",
       "         0.7182721 ,  0.76088401,  0.73527529,  0.71496587,  0.74237388,\n",
       "         0.72664438,  0.73905737,  0.72477276,  0.71696055,  0.71915954,\n",
       "         0.92666496,  0.93872543,  0.93398781,  0.93793952,  0.92849959,\n",
       "         0.92827786,  0.93248311,  0.93410576,  0.9283375 ,  0.93406973,\n",
       "         0.93046398,  0.9353672 ,  0.93023285,  0.93468059,  0.93346453,\n",
       "         0.93559473,  0.93065208,  0.92645729,  0.93247151,  0.92918027]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((labels, silhouettes(labels=labels, n_samples=X_sc.shape[0])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
